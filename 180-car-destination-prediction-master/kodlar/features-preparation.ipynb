{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "import os\n",
    "import pandas as pd\n",
    "import geohash\n",
    "\n",
    "sc = pyspark.SparkContext()\n",
    "spark = pyspark.SQLContext(sc)\n",
    "\n",
    "working_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we read the data processed in the notebook *\"data-cleansing.ipynb\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+---------+---------+---------+\n",
      "|eventTimeStart     |latStart  |lonStart |latEnd   |lonEnd   |\n",
      "+-------------------+----------+---------+---------+---------+\n",
      "|2017-03-22 16:50:25|38.7735368|-9.168737|38.76522 |-9.098054|\n",
      "|2017-05-24 12:20:56|47.409291 |8.546942 |47.423743|8.555213 |\n",
      "|2017-05-24 12:21:08|47.409291 |8.546942 |47.423743|8.555213 |\n",
      "|2017-05-24 12:21:17|47.409291 |8.546942 |47.423743|8.555213 |\n",
      "|2017-05-24 12:21:24|47.409291 |8.546942 |47.423743|8.555213 |\n",
      "|2017-05-24 12:21:32|47.409291 |8.546942 |47.423743|8.555213 |\n",
      "|2017-05-24 12:21:37|47.409291 |8.546942 |47.423743|8.555213 |\n",
      "|2017-05-24 12:22:08|47.409291 |8.546942 |47.423743|8.555213 |\n",
      "|2017-05-24 12:22:23|47.409291 |8.546942 |47.423743|8.555213 |\n",
      "|2017-05-24 12:22:27|47.409291 |8.546942 |47.423743|8.555213 |\n",
      "+-------------------+----------+---------+---------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#processedDf = pd.read_csv('processed_dataset.csv')\n",
    "# Remove first column which contains a no needed index\n",
    "#processedDf = processedDf.drop(processedDf.columns[0], axis=1)\n",
    "# Remove eventTimeEnd because we won't use it\n",
    "#processedDf = processedDf.drop('eventTimeEnd', axis=1)\n",
    "#processedDf.head(10)\n",
    "# Load parquet file into dataframe\n",
    "processedDf = spark.read.csv(\"file://\" + working_dir + \"/processed-dataset.csv\", header=True)\n",
    "processedDf = processedDf.select(['eventTimeStart', 'latStart','lonStart', 'latEnd', 'lonEnd'])\n",
    "processedDf.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation specification\n",
    "\n",
    "Given, a certain granularity in location (geohash length g), granularity in time (bins per day b) and a chosen wideness (w) of the neighbourhood we want to look at, the aggregated data in the end should have the following columns:\n",
    "\n",
    "**\"geohash\"**\n",
    "\n",
    "Geohash with length g (categorical feature). This column will not actually be used in the prediction. It is just an id and can be used when calculating the distances between the geohashes.\n",
    "\n",
    "**\"time_cat\"**\n",
    "\n",
    "Time of the day as a categorical feature. If $b = 24$ (one bin for every hour), then \"time_cat\" for a pickup at 14:20:00 should be the string \"14:00\". If $b = 96$ (one bin for every quarter of an hour), then \"time_cat\" for a pickup at 14:20:00 should be the string '14:15'.\n",
    "\n",
    "**\"time_num\"**\n",
    "\n",
    "Time of the day as a (binned!) floating point number between 0 and 1, where the center of the bin is converted to a floating point number between 0 and 1. So if $b = 24$, then \"time_num\" for a pickup at 14:20:00 should be $14.5\\,/\\,24 =  0.6042$. If $b = 96$, it should translate to $14.375\\,/\\,24 = 0.5990$.\n",
    "\n",
    "**\"time_cos\"**\n",
    "\n",
    "The binned \"time_num\" variable converted to a cosine version so that time nicely 'loops' rather than going saw-like when it traverses midnight. See the figure below. This transformation doesn't have any magic powers, but it can make it easier for a model to find the right patterns. \"time_cos\" = $\\cos(\\textrm{time_num} \\cdot 2\\pi)$. So for 24 bins, 14:20:00 would translate to $\\cos(0.6042 \\cdot 2\\pi) = -0.7932$.\n",
    "\n",
    "[cyclic-transf]: ./images/cyclic-numeric-feature-transformation.png\n",
    "![alt text][cyclic-transf]\n",
    "\n",
    "**\"time_sin\"**\n",
    "\n",
    "Same thing as 4) but then with sine. So, \"time_sin\" = $\\sin(\\textrm{time_num} \\cdot 2 \\pi)$. For 24 bins per day, 14:20:00 would translate to $\\sin(0.6042 \\cdot 2 \\pi) = -0.6089$.\n",
    "\n",
    "**\"day_cat\"**\n",
    "\n",
    "Day of the week as a categorical feature: \"Monday\", \"Tuesday\", etc.\n",
    "\n",
    "**\"day_num\"**\n",
    "\n",
    "Day of the week as a numerical feature going from 0 (Monday morning, start of the week) to 1 (Sunday night), European style. With 24 bins, Tuesday afternoon 14:20:00 would translate to $(1 + \\frac{14.5}{24})\\,/\\,7 = 0.2292$.\n",
    "\n",
    "**\"day_cos\"**\n",
    "\n",
    "Binned \"day_num\" variable converted to a cosine version. \"day_cos\" = $\\cos(\\textrm{day_num} \\cdot 2\\pi)$\n",
    "\n",
    "**\"day_sin\"**\n",
    "\n",
    "Binned \"day_num\"variable converted to a sine version. \"day_sin\" = $\\sin(\\textrm{day_num} \\cdot 2\\pi)$\n",
    "\n",
    "**\"weekend\"**\n",
    "\n",
    "0 if weekday, 1 if weekend (Saturday/Sunday)\n",
    "\n",
    "**Location features**\n",
    "\n",
    "Latitude and longitude of the center of the geohash the record was bucketed in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions for cleaning and feature extraction/generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Needed libraries\n",
    "import time\n",
    "from datetime import date\n",
    "import math\n",
    "\n",
    "def date_extractor(date_str,b,minutes_per_bin):\n",
    "    # Takes a datetime object as a parameter\n",
    "    # and extracts and returns a tuple of the form: (as per the data specification)\n",
    "    # (time_cat, time_num, time_cos, time_sin, day_cat, day_num, day_cos, day_sin, weekend)\n",
    "    # Split date string into list of date, time\n",
    "    \n",
    "    d = date_str.split()\n",
    "    \n",
    "    #safety check\n",
    "    if len(d) != 2:\n",
    "        return tuple([None,])\n",
    "    \n",
    "    # TIME (eg. for 16:56:20 and 15 mins per bin)\n",
    "    #list of hour,min,sec (e.g. [16,56,20])\n",
    "    time_list = [int(t) for t in d[1].split(':')]\n",
    "    \n",
    "    #safety check\n",
    "    if len(time_list) != 3:\n",
    "        return tuple([None,])\n",
    "    \n",
    "    # calculate number of minute into the day (eg. 1016)\n",
    "    num_minutes = time_list[0] * 60 + time_list[1]\n",
    "    \n",
    "    # Time of the start of the bin\n",
    "    time_bin = num_minutes / minutes_per_bin     # eg. 1005\n",
    "    hour_bin = num_minutes / 60                  # eg. 16\n",
    "    min_bin = (time_bin * minutes_per_bin) % 60  # eg. 45\n",
    "    \n",
    "    #get time_cat\n",
    "    hour_str = str(hour_bin) if hour_bin / 10 > 0 else \"0\" + str(hour_bin)  # eg. \"16\"\n",
    "    min_str = str(min_bin) if min_bin / 10 > 0 else \"0\" + str(min_bin)      # eg. \"45\"\n",
    "    time_cat = hour_str + \":\" + min_str                                     # eg. \"16:45\"\n",
    "    \n",
    "    # Get a floating point representation of the center of the time bin\n",
    "    time_num = (hour_bin*60 + min_bin + minutes_per_bin / 2.0)/(60*24)      # eg. 0.7065972222222222\n",
    "    \n",
    "    time_cos = math.cos(time_num * 2 * math.pi)\n",
    "    time_sin = math.sin(time_num * 2 * math.pi)\n",
    "    \n",
    "    # DATE\n",
    "    # Parse year, month, day\n",
    "    date_list = d[0].split('-')\n",
    "    d_obj = date(int(date_list[0]),int(date_list[1]),int(date_list[2]))\n",
    "    day_to_str = {0: \"Monday\",\n",
    "                  1: \"Tuesday\",\n",
    "                  2: \"Wednesday\",\n",
    "                  3: \"Thursday\",\n",
    "                  4: \"Friday\",\n",
    "                  5: \"Saturday\",\n",
    "                  6: \"Sunday\"}\n",
    "    day_of_week = d_obj.weekday()\n",
    "    day_cat = day_to_str[day_of_week]\n",
    "    day_num = (day_of_week + time_num)/7.0\n",
    "    day_cos = math.cos(day_num * 2 * math.pi)\n",
    "    day_sin = math.sin(day_num * 2 * math.pi)\n",
    "    \n",
    "    year = d_obj.year\n",
    "    month = d_obj.month\n",
    "    day = d_obj.day\n",
    "    \n",
    "    weekend = 0\n",
    "    #check if it is the weekend\n",
    "    if day_of_week in [5,6]:\n",
    "        weekend = 1\n",
    "       \n",
    "    return (year, month, day, time_cat, time_num, time_cos, time_sin, day_cat, day_num, day_cos, day_sin, weekend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_cleaner(zipped_row):\n",
    "    # takes a tuple (row,g,b,minutes_per_bin) as a parameter and returns a tuple of the form:\n",
    "    # (time_cat, time_num, time_cos, time_sin, day_cat, day_num, day_cos, day_sin, weekend,geohash)\n",
    "    row = zipped_row[0]\n",
    "    g = zipped_row[1]\n",
    "    b = zipped_row[2]\n",
    "    minutes_per_bin = zipped_row[3]\n",
    "    # The indices of trip-start datetime, latitude start, longitude start, latitude end and longitude end respectively\n",
    "    indices = (0, 1, 2, 3, 4)\n",
    "    \n",
    "    #safety check: make sure row has enough features\n",
    "    if len(row) < 5:\n",
    "        return None\n",
    "    \n",
    "    #extract day of the week and hour\n",
    "    date_str = row[indices[0]]\n",
    "    clean_date = date_extractor(date_str,b,minutes_per_bin)\n",
    "    #get geo hash\n",
    "\n",
    "    lat_start = float(row[indices[1]])\n",
    "    lon_start = float(row[indices[2]])\n",
    "    lat_end = float(row[indices[3]])\n",
    "    lon_end = float(row[indices[4]])\n",
    "    location_start = None\n",
    "    location_end = None\n",
    "    location_start = geohash.encode(lat_start,lon_start, g)    \n",
    "    location_end = geohash.encode(lat_end,lon_end, g)\n",
    "    x_start = math.cos(lat_start) * math.cos(lon_start)\n",
    "    y_start = math.cos(lat_start) * math.sin(lon_start) \n",
    "    z_start = math.sin(lat_start) \n",
    "\n",
    "    return tuple(list(clean_date)+[x_start]+[y_start]+[z_start]+[location_start]+[location_end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = 9 #geohash length, a 1.2km x 609.4m square area\n",
    "b = 12 # number of time bins per day\n",
    "# Note: b must evenly divide 60\n",
    "minutes_per_bin = int((24 / float(b)) * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean data create and create features as specified above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedRDD = processedDf.rdd\n",
    "processedRDD = processedRDD \\\n",
    "                .map(lambda row: (row, g, b, minutes_per_bin)) \\\n",
    "                .map(data_cleaner) \\\n",
    "                .filter(lambda row: row != None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuredDf = spark.createDataFrame(processedRDD, ['year', 'month', 'day', 'time_cat', 'time_num', 'time_cos', \\\n",
    "                                                  'time_sin', 'day_cat', 'day_num', 'day_cos', 'day_sin', 'weekend', \\\n",
    "                                                  'x_start', 'y_start', 'z_start','location_start', 'location_end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>time_cat</th>\n",
       "      <th>time_num</th>\n",
       "      <th>time_cos</th>\n",
       "      <th>time_sin</th>\n",
       "      <th>day_cat</th>\n",
       "      <th>day_num</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>weekend</th>\n",
       "      <th>x_start</th>\n",
       "      <th>y_start</th>\n",
       "      <th>z_start</th>\n",
       "      <th>location_start</th>\n",
       "      <th>location_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>16.833333333333332:49.999999999999886</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.173648</td>\n",
       "      <td>-0.984808</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0.396825</td>\n",
       "      <td>-0.797133</td>\n",
       "      <td>0.603804</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.460713</td>\n",
       "      <td>-0.120608</td>\n",
       "      <td>0.879316</td>\n",
       "      <td>eyckx6e80</td>\n",
       "      <td>eycs8byzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>12.333333333333334:20.0</td>\n",
       "      <td>0.569444</td>\n",
       "      <td>-0.906308</td>\n",
       "      <td>-0.422618</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0.367063</td>\n",
       "      <td>-0.670981</td>\n",
       "      <td>0.741474</td>\n",
       "      <td>0</td>\n",
       "      <td>0.612977</td>\n",
       "      <td>-0.738237</td>\n",
       "      <td>-0.281542</td>\n",
       "      <td>u0qjdqxen</td>\n",
       "      <td>u0qjf9jxq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>12.35:21.0</td>\n",
       "      <td>0.570833</td>\n",
       "      <td>-0.902585</td>\n",
       "      <td>-0.430511</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0.367262</td>\n",
       "      <td>-0.671905</td>\n",
       "      <td>0.740637</td>\n",
       "      <td>0</td>\n",
       "      <td>0.612977</td>\n",
       "      <td>-0.738237</td>\n",
       "      <td>-0.281542</td>\n",
       "      <td>u0qjdqxen</td>\n",
       "      <td>u0qjf9jxq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>12.35:21.0</td>\n",
       "      <td>0.570833</td>\n",
       "      <td>-0.902585</td>\n",
       "      <td>-0.430511</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0.367262</td>\n",
       "      <td>-0.671905</td>\n",
       "      <td>0.740637</td>\n",
       "      <td>0</td>\n",
       "      <td>0.612977</td>\n",
       "      <td>-0.738237</td>\n",
       "      <td>-0.281542</td>\n",
       "      <td>u0qjdqxen</td>\n",
       "      <td>u0qjf9jxq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>12.35:21.0</td>\n",
       "      <td>0.570833</td>\n",
       "      <td>-0.902585</td>\n",
       "      <td>-0.430511</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0.367262</td>\n",
       "      <td>-0.671905</td>\n",
       "      <td>0.740637</td>\n",
       "      <td>0</td>\n",
       "      <td>0.612977</td>\n",
       "      <td>-0.738237</td>\n",
       "      <td>-0.281542</td>\n",
       "      <td>u0qjdqxen</td>\n",
       "      <td>u0qjf9jxq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>12.35:21.0</td>\n",
       "      <td>0.570833</td>\n",
       "      <td>-0.902585</td>\n",
       "      <td>-0.430511</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0.367262</td>\n",
       "      <td>-0.671905</td>\n",
       "      <td>0.740637</td>\n",
       "      <td>0</td>\n",
       "      <td>0.612977</td>\n",
       "      <td>-0.738237</td>\n",
       "      <td>-0.281542</td>\n",
       "      <td>u0qjdqxen</td>\n",
       "      <td>u0qjf9jxq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>12.35:21.0</td>\n",
       "      <td>0.570833</td>\n",
       "      <td>-0.902585</td>\n",
       "      <td>-0.430511</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0.367262</td>\n",
       "      <td>-0.671905</td>\n",
       "      <td>0.740637</td>\n",
       "      <td>0</td>\n",
       "      <td>0.612977</td>\n",
       "      <td>-0.738237</td>\n",
       "      <td>-0.281542</td>\n",
       "      <td>u0qjdqxen</td>\n",
       "      <td>u0qjf9jxq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>12.366666666666667:22.0</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>-0.898794</td>\n",
       "      <td>-0.438371</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0.367460</td>\n",
       "      <td>-0.672828</td>\n",
       "      <td>0.739799</td>\n",
       "      <td>0</td>\n",
       "      <td>0.612977</td>\n",
       "      <td>-0.738237</td>\n",
       "      <td>-0.281542</td>\n",
       "      <td>u0qjdqxen</td>\n",
       "      <td>u0qjf9jxq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>12.366666666666667:22.0</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>-0.898794</td>\n",
       "      <td>-0.438371</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0.367460</td>\n",
       "      <td>-0.672828</td>\n",
       "      <td>0.739799</td>\n",
       "      <td>0</td>\n",
       "      <td>0.612977</td>\n",
       "      <td>-0.738237</td>\n",
       "      <td>-0.281542</td>\n",
       "      <td>u0qjdqxen</td>\n",
       "      <td>u0qjf9jxq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>12.366666666666667:22.0</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>-0.898794</td>\n",
       "      <td>-0.438371</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0.367460</td>\n",
       "      <td>-0.672828</td>\n",
       "      <td>0.739799</td>\n",
       "      <td>0</td>\n",
       "      <td>0.612977</td>\n",
       "      <td>-0.738237</td>\n",
       "      <td>-0.281542</td>\n",
       "      <td>u0qjdqxen</td>\n",
       "      <td>u0qjf9jxq</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day                               time_cat  time_num  \\\n",
       "0  2017      3   22  16.833333333333332:49.999999999999886  0.777778   \n",
       "1  2017      5   24                12.333333333333334:20.0  0.569444   \n",
       "2  2017      5   24                             12.35:21.0  0.570833   \n",
       "3  2017      5   24                             12.35:21.0  0.570833   \n",
       "4  2017      5   24                             12.35:21.0  0.570833   \n",
       "5  2017      5   24                             12.35:21.0  0.570833   \n",
       "6  2017      5   24                             12.35:21.0  0.570833   \n",
       "7  2017      5   24                12.366666666666667:22.0  0.572222   \n",
       "8  2017      5   24                12.366666666666667:22.0  0.572222   \n",
       "9  2017      5   24                12.366666666666667:22.0  0.572222   \n",
       "\n",
       "   time_cos  time_sin    day_cat   day_num   day_cos   day_sin  weekend  \\\n",
       "0  0.173648 -0.984808  Wednesday  0.396825 -0.797133  0.603804        0   \n",
       "1 -0.906308 -0.422618  Wednesday  0.367063 -0.670981  0.741474        0   \n",
       "2 -0.902585 -0.430511  Wednesday  0.367262 -0.671905  0.740637        0   \n",
       "3 -0.902585 -0.430511  Wednesday  0.367262 -0.671905  0.740637        0   \n",
       "4 -0.902585 -0.430511  Wednesday  0.367262 -0.671905  0.740637        0   \n",
       "5 -0.902585 -0.430511  Wednesday  0.367262 -0.671905  0.740637        0   \n",
       "6 -0.902585 -0.430511  Wednesday  0.367262 -0.671905  0.740637        0   \n",
       "7 -0.898794 -0.438371  Wednesday  0.367460 -0.672828  0.739799        0   \n",
       "8 -0.898794 -0.438371  Wednesday  0.367460 -0.672828  0.739799        0   \n",
       "9 -0.898794 -0.438371  Wednesday  0.367460 -0.672828  0.739799        0   \n",
       "\n",
       "    x_start   y_start   z_start location_start location_end  \n",
       "0 -0.460713 -0.120608  0.879316      eyckx6e80    eycs8byzz  \n",
       "1  0.612977 -0.738237 -0.281542      u0qjdqxen    u0qjf9jxq  \n",
       "2  0.612977 -0.738237 -0.281542      u0qjdqxen    u0qjf9jxq  \n",
       "3  0.612977 -0.738237 -0.281542      u0qjdqxen    u0qjf9jxq  \n",
       "4  0.612977 -0.738237 -0.281542      u0qjdqxen    u0qjf9jxq  \n",
       "5  0.612977 -0.738237 -0.281542      u0qjdqxen    u0qjf9jxq  \n",
       "6  0.612977 -0.738237 -0.281542      u0qjdqxen    u0qjf9jxq  \n",
       "7  0.612977 -0.738237 -0.281542      u0qjdqxen    u0qjf9jxq  \n",
       "8  0.612977 -0.738237 -0.281542      u0qjdqxen    u0qjf9jxq  \n",
       "9  0.612977 -0.738237 -0.281542      u0qjdqxen    u0qjf9jxq  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuredPandas = featuredDf.toPandas()\n",
    "featuredPandas.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featuredPandas.to_csv('featured-dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
